#! /usr/bin/env python2

import subprocess
import tempfile
import configparser
import datetime
import time
import os
import sys
import logging
import logging.config


realpath = os.path.dirname(os.path.realpath(__file__))

def setup_logging(default_level = logging.INFO):
    import yaml
    with open(os.path.join(realpath, 'logging.yaml')) as fh:
        config = yaml.load(fh)
        logging.config.dictConfig(config)

def generate_magnet_links(link_path):
    ret = subprocess.Popen([os.path.join(realpath, 'get_magnet_links.py')],
            stdout=subprocess.PIPE)
    stdoutdata, stderrdata = ret.communicate()

    with open(link_path, 'w') as fh:
        fh.write(stdoutdata)
        
    logging.info('magnet links updated')

def crawl(stat_path, link_path=''):
    if not os.path.exists(stat_path) or not os.path.isdir(stat_path):
        raise Exception('%s is not a directory for storing statistics' % stat_path)

    config_file     = tempfile.mkstemp('crawlerd_config.ini')
    torrent_path    = tempfile.mkdtemp('crawlerd_torrent')
    now = datetime.datetime.now().strftime('%Y%m%d-%H:%M:%S')

    config = configparser.ConfigParser()
    config['settings'] = {
            'session_number': 10,
            'session_interval': 6,
            'update_interval': 10,
            'stat_save_path': os.path.join(stat_path, '%s.json' % now),
            'torrent_save_path': torrent_path,
            'magnet_links_path': link_path,
            'save_interval': 10,
            }

    with open(config_file[1], 'w') as config_fh:
        config.write(config_fh)

    ret = subprocess.Popen([os.path.join(realpath, 'client'), config_file[1]],
            stdout=subprocess.PIPE)

    for l in ret.stdout:
        logging.info(l.rstrip())
    ret.wait()

    time.sleep(4)
    os.remove(config_file[1])
    os.removedirs(torrent_path)

if __name__ == "__main__":
    setup_logging()
    start_time = datetime.datetime.now()

    magnet_link_path = './magnet_links.txt'
    magnet_generate_interval = datetime.timedelta(hours=3)

    generate_magnet_links(magnet_link_path)
    while True:
        elapsed = datetime.datetime.now() - start_time
        if elapsed > magnet_generate_interval:
            start_time = datetime.datetime.now()
            generate_magnet_links(magnet_link_path)

        crawl('statistics', magnet_link_path)


